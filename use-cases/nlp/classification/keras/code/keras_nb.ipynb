{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification using Keras with Neptune tracking\n",
    "Notebook inspired from https://keras.io/examples/nlp/text_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Neptune) Install the neptune-notebooks widget (optional)\n",
    "The neptune-notebooks jupyter extension lets you version, manage and share notebook checkpoints in your projects, without leaving your notebook.  \n",
    "[Read the docs](https://docs.neptune.ai/integrations-and-supported-tools/ide-and-notebooks/jupyter-lab-and-jupyter-notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U neptune-tensorflow-keras numpy pydot tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_files(source: str, destination: str) -> None:\n",
    "    \"\"\"Extracts files from the source archive to the destination path\n",
    "\n",
    "    Args:\n",
    "        source (str): Archive file path\n",
    "        destination (str): Extract destination path\n",
    "    \"\"\"\n",
    "\n",
    "    import tarfile\n",
    "\n",
    "    print(\"Extracting data...\")\n",
    "    with tarfile.open(source) as f:\n",
    "        f.extractall(destination)\n",
    "\n",
    "\n",
    "def prep_data(imdb_folder: str, dest_path: str) -> None:\n",
    "    \"\"\"Removes unnecessary folders/files and renames source folder\n",
    "\n",
    "    Args:\n",
    "        imdb_folder (str): Path of the aclImdb folder\n",
    "        dest_name (str): Destination folder to which the aclImdb folder has to be renamed to\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    shutil.rmtree(f\"{imdb_folder}/train/unsup\")\n",
    "    os.remove(f\"{imdb_folder.rsplit('/', maxsplit=1)[0]}/aclImdb_v1.tar.gz\")\n",
    "\n",
    "    if os.path.exists(dest_path):\n",
    "        shutil.rmtree(dest_path)\n",
    "\n",
    "    os.rename(imdb_folder, dest_path)\n",
    "    print(f\"{imdb_folder} renamed to {dest_path}\")\n",
    "\n",
    "\n",
    "def build_model(model_params: dict, data_params: dict):\n",
    "    \"\"\"Accepts model and data parameters to build and compile a keras model\n",
    "\n",
    "    Args:\n",
    "        model_params (dict): Model parameters\n",
    "        data_params (dict): Data parameters\n",
    "\n",
    "    Returns:\n",
    "        A compiled keras model\n",
    "    \"\"\"\n",
    "\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    # A integer input for vocab indices.\n",
    "    inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "    # Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "    # 'embedding_dim'.\n",
    "    x = layers.Embedding(data_params[\"max_features\"], data_params[\"embedding_dim\"])(inputs)\n",
    "    x = layers.Dropout(model_params[\"dropout\"])(x)\n",
    "\n",
    "    # Conv1D + global max pooling\n",
    "    x = layers.Conv1D(\n",
    "        data_params[\"embedding_dim\"],\n",
    "        model_params[\"kernel_size\"],\n",
    "        padding=\"valid\",\n",
    "        activation=model_params[\"activation\"],\n",
    "        strides=model_params[\"strides\"],\n",
    "    )(x)\n",
    "    x = layers.Conv1D(\n",
    "        data_params[\"embedding_dim\"],\n",
    "        model_params[\"kernel_size\"],\n",
    "        padding=\"valid\",\n",
    "        activation=model_params[\"activation\"],\n",
    "        strides=model_params[\"strides\"],\n",
    "    )(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "    # We add a vanilla hidden layer:\n",
    "    x = layers.Dense(data_params[\"embedding_dim\"], activation=model_params[\"activation\"])(x)\n",
    "    x = layers.Dropout(model_params[\"dropout\"])(x)\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "    keras_model = tf.keras.Model(inputs, predictions)\n",
    "\n",
    "    # Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "    keras_model.compile(\n",
    "        loss=model_params[\"loss\"],\n",
    "        optimizer=model_params[\"optimizer\"],\n",
    "        metrics=model_params[\"metrics\"],\n",
    "    )\n",
    "\n",
    "    return keras_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Import Neptune and initialize a project\n",
    "**A project is a collection of runs, models, and other metadata created by project members.** Typically you should create one project per machine learning task, to make it easy to compare runs that are connected to building certain kinds of ML model.  \n",
    "[Read the docs](https://docs.neptune.ai/you-should-know/core-concepts#project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEPTUNE_PROJECT\"] = \"showcase/project-text-classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need a Neptune API token to be able to log to Neptune.\n",
    "Read how to get and use one [here](https://docs.neptune.ai/setup/setting_api_token/#setting-your-api-token).\n",
    "\n",
    "**or** \n",
    "\n",
    "If you don't have an API token, you can use the `neptune.ANONYMOUS_API_TOKEN` to log to a public project.  \n",
    "To log anonymously to a public project, set it as your environment variable as below:\n",
    "\n",
    "```python\n",
    "os.environ[\"NEPTUNE_API_TOKEN\"] = neptune.ANONYMOUS_API_TOKEN\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/showcase/project-text-classification/\n"
     ]
    }
   ],
   "source": [
    "import neptune\n",
    "\n",
    "project = neptune.init_project()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "We are using the IMDB sentiment analysis data available at https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz. For the purposes of this demo, we've uploaded this data to S3 at https://neptune-examples.s3.us-east-2.amazonaws.com/data/text-classification/aclImdb_v1.tar.gz and will be downloading it from there."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Track datasets using Neptune\n",
    "Neptune lets you track pointers to datasets, models, and other artifacts stored locally or in S3.  \n",
    "[Read the docs](https://docs.neptune.ai/how-to-guides/data-versioning)\n",
    "\n",
    "Since this dataset will be used among all the runs in the project, we track it at the project level.\n",
    "Read more about logging project-level metadata [here](https://docs.neptune.ai/logging/project_metadata/#logging-project-level-metadata).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project[\"keras/data/files\"].track_files(\n",
    "    \"s3://neptune-examples/data/text-classification/aclImdb_v1.tar.gz\"\n",
    ")\n",
    "project.sync()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Download files from S3 using Neptune\n",
    "You can also download tracked files from S3 using Neptune, without having to write boilerplate boto3 code.\n",
    "Read the artifact API reference to know more: https://docs.neptune.ai/api/field_types/#download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading data...\")\n",
    "project[\"keras/data/files\"].download(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: '../aclImdb' -> '../data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m extract_files(source\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../aclImdb_v1.tar.gz\u001b[39m\u001b[39m\"\u001b[39m, destination\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m prep_data(imdb_folder\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../aclImdb\u001b[39;49m\u001b[39m\"\u001b[39;49m, dest_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../data\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 31\u001b[0m, in \u001b[0;36mprep_data\u001b[1;34m(imdb_folder, dest_path)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(dest_path):\n\u001b[0;32m     30\u001b[0m     shutil\u001b[39m.\u001b[39mrmtree(dest_path)\n\u001b[1;32m---> 31\u001b[0m os\u001b[39m.\u001b[39;49mrename(imdb_folder, dest_path)\n\u001b[0;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mimdb_folder\u001b[39m}\u001b[39;00m\u001b[39m renamed to \u001b[39m\u001b[39m{\u001b[39;00mdest_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: '../aclImdb' -> '../data'"
     ]
    }
   ],
   "source": [
    "extract_files(source=\"../aclImdb_v1.tar.gz\", destination=\"..\")\n",
    "prep_data(imdb_folder=\"../aclImdb\", dest_path=\"../data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Neptune) Upload dataset sample to Neptune project\n",
    "In addition to tracking external files, you can also upload them directly to Neptune.\n",
    "Such uploaded files can be visualized directly in the Neptune app.  \n",
    "[Read more here](https://docs.neptune.ai/logging/files/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "base_namespace = \"keras/data/sample/\"\n",
    "\n",
    "project[base_namespace][\"train/pos\"].upload(\n",
    "    f\"../data/train/pos/{random.choice(os.listdir('../data/train/pos'))}\"\n",
    ")\n",
    "project[base_namespace][\"train/neg\"].upload(\n",
    "    f\"../data/train/neg/{random.choice(os.listdir('../data/train/neg'))}\"\n",
    ")\n",
    "project[base_namespace][\"test/pos\"].upload(\n",
    "    f\"../data/test/pos/{random.choice(os.listdir('../data/test/pos'))}\"\n",
    ")\n",
    "project[base_namespace][\"test/neg\"].upload(\n",
    "    f\"../data/test/neg/{random.choice(os.listdir('../data/test/neg'))}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Initialize a run\n",
    "**A run is a namespace inside a project where you log metadata.** Typically, you create a run every time you execute a script that does model training, re-training, or inference.  \n",
    "[Read the docs](https://docs.neptune.ai/you-should-know/core-concepts#run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\miniconda3\\envs\\py38\\lib\\site-packages\\neptune\\common\\warnings.py:62: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-379\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(name=\"Keras text classification\", tags=[\"keras\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Neptune) Log data metadata to run\n",
    "You can log nested dictionaries to create custom nested namespaces.  \n",
    "[Read the docs](https://docs.neptune.ai/logging/methods/#essential-logging-methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    \"batch_size\": 32,\n",
    "    \"validation_split\": 0.2,\n",
    "    \"max_features\": 2000,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"sequence_length\": 500,\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"data/params\"] = data_params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Neptune) Track dataset at the run-level\n",
    "We can fetch the dataset from the project metadata and track it at the run level using the `fetch()` method.  \n",
    "[`fetch()` API reference](https://docs.neptune.ai/api/field_types/#fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"data/files\"] = project[\"keras/data/files\"].fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Number of batches in raw_train_ds: 625\n",
      "Number of batches in raw_val_ds: 157\n",
      "Number of batches in raw_test_ds: 782\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds, raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"../data/train\",\n",
    "    batch_size=data_params[\"batch_size\"],\n",
    "    validation_split=data_params[\"validation_split\"],\n",
    "    subset=\"both\",\n",
    "    seed=data_params[\"seed\"],\n",
    ")\n",
    "\n",
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"../data/test\", batch_size=data_params[\"batch_size\"]\n",
    ")\n",
    "\n",
    "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    import string\n",
    "    import re\n",
    "\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
    "\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=data_params[\"max_features\"],\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=data_params[\"sequence_length\"],\n",
    ")\n",
    "\n",
    "text_ds = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "\n",
    "# Vectorize the data.\n",
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)\n",
    "\n",
    "# Do async prefetching / buffering of the data for best performance on GPU.\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Register a model and create a new model version\n",
    "With Neptune's model registry, you can store your ML models in a central location and collaboratively manage their lifecycle.  \n",
    "[Read the docs](https://docs.neptune.ai/how-to-guides/model-registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\miniconda3\\envs\\py38\\lib\\site-packages\\neptune\\common\\warnings.py:62: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-11\n"
     ]
    }
   ],
   "source": [
    "from neptune.exceptions import NeptuneModelKeyAlreadyExistsError\n",
    "\n",
    "project_key = project[\"sys/id\"].fetch()\n",
    "\n",
    "try:\n",
    "    model = neptune.init_model(name=\"keras\", key=\"KER\")\n",
    "    model.stop()\n",
    "except NeptuneModelKeyAlreadyExistsError:\n",
    "    # If it already exists, we don't have to do anything.\n",
    "    pass\n",
    "\n",
    "model_version = neptune.init_model_version(model=f\"{project_key}-KER\", name=\"keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"dropout\": 0.5,\n",
    "    \"strides\": 2,\n",
    "    \"activation\": \"relu\",\n",
    "    \"kernel_size\": 5,\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"metrics\": [\"accuracy\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\miniconda3\\envs\\py38\\lib\\site-packages\\neptune\\common\\warnings.py:62: NeptuneUnsupportedType: You're attempting to log a type that is not directly supported by Neptune (<class 'list'>).\n",
      "        Convert the value to a supported type, such as a string or float, or use stringify_unsupported(obj)\n",
      "        for dictionaries or collections that contain unsupported values.\n",
      "        For more, see https://docs.neptune.ai/help/value_of_unsupported_type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_version[\"params\"] = model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = build_model(model_params, data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Neptune) Initialize the Neptune callback\n",
    "The Neptune–Keras integration logs the following metadata automatically:\n",
    "\n",
    "* Model summary\n",
    "* Parameters of the optimizer used for training the model\n",
    "* Parameters passed to Model.fit during the training\n",
    "* Current learning rate at every epoch\n",
    "* Hardware consumption and stdout/stderr output during training\n",
    "* Training code and Git information\n",
    "\n",
    "Read more about the Neptune–Keras integration here: https://docs.neptune.ai/integrations/keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "neptune_callback = NeptuneCallback(run=run, log_model_diagram=True, log_on_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    \"epochs\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 39s 57ms/step - loss: 0.5525 - accuracy: 0.6670 - val_loss: 0.3319 - val_accuracy: 0.8586\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.2704 - accuracy: 0.8918 - val_loss: 0.3928 - val_accuracy: 0.8508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7dea190a0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the train and test datasets.\n",
    "keras_model.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=training_params[\"epochs\"], callbacks=neptune_callback\n",
    ")\n",
    "# Training parameters are logged automatically to Neptune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3840 - accuracy: 0.8517\n"
     ]
    }
   ],
   "source": [
    "# We save the accuracy of the  model to be able to evaluate it against the current model in production later in the code\n",
    "_, curr_model_acc = keras_model.evaluate(test_ds, callbacks=neptune_callback)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Associate run with model and vice-versa\n",
    "We can fetch metadata from the run's `sys` namespace and add those to the model_version to be able to link model versions with the runs that created them, and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'TXTCLF-379', 'name': 'Keras text classification', 'url': 'https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-379'}\n"
     ]
    }
   ],
   "source": [
    "run_meta = {\n",
    "    \"id\": run[\"sys/id\"].fetch(),\n",
    "    \"name\": run[\"sys/name\"].fetch(),\n",
    "    \"url\": run.get_url(),\n",
    "}\n",
    "\n",
    "print(run_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version[\"run\"] = run_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'TXTCLF-KER-11', 'name': 'keras', 'url': 'https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-11'}\n"
     ]
    }
   ],
   "source": [
    "model_version_meta = {\n",
    "    \"id\": model_version[\"sys/id\"].fetch(),\n",
    "    \"name\": model_version[\"sys/name\"].fetch(),\n",
    "    \"url\": model_version.get_url(),\n",
    "}\n",
    "\n",
    "print(model_version_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[\"training/model/meta\"] = model_version_meta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Upload serialized model and model weights to Neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version[\"serialized_model\"] = keras_model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.save_weights(\"model_weights.h5\")\n",
    "model_version[\"model_weights\"].upload(\"model_weights.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Update model stage\n",
    "We can update the model stage both in the app and through the API.  \n",
    "[Read the docs](https://docs.neptune.ai/model_registry/managing_stage/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version.change_stage(\"staging\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Wait for all operations to reach with Neptune servers\n",
    "Since Neptune sends data to servers asynchronously by default, we need to wait for operations to complete if we want to refer to fields/objects that were sent to Neptune earlier in the same code.  \n",
    "Read about the `wait()` and `sync()` methods here: https://docs.neptune.ai/logging/wait_and_sync/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Neptune) Promote best model to production"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Fetch current champion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/metadata\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys/creation_time</th>\n",
       "      <th>sys/id</th>\n",
       "      <th>sys/model_id</th>\n",
       "      <th>sys/modification_time</th>\n",
       "      <th>sys/monitoring_time</th>\n",
       "      <th>sys/name</th>\n",
       "      <th>sys/owner</th>\n",
       "      <th>sys/ping_time</th>\n",
       "      <th>sys/running_time</th>\n",
       "      <th>sys/size</th>\n",
       "      <th>...</th>\n",
       "      <th>params/dropout</th>\n",
       "      <th>params/kernel_size</th>\n",
       "      <th>params/loss</th>\n",
       "      <th>params/metrics</th>\n",
       "      <th>params/optimizer</th>\n",
       "      <th>params/strides</th>\n",
       "      <th>run/id</th>\n",
       "      <th>run/name</th>\n",
       "      <th>run/url</th>\n",
       "      <th>serialized_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-06 16:34:05.166000+00:00</td>\n",
       "      <td>TXTCLF-KER-11</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-03-06 16:45:27.866000+00:00</td>\n",
       "      <td>658</td>\n",
       "      <td>keras</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-03-06 16:56:32.444000+00:00</td>\n",
       "      <td>1347.211</td>\n",
       "      <td>10993265.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>TXTCLF-379</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-06 12:43:16.770000+00:00</td>\n",
       "      <td>TXTCLF-KER-10</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-06 12:45:01.981000+00:00</td>\n",
       "      <td>92</td>\n",
       "      <td>keras</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-06 12:45:01.981000+00:00</td>\n",
       "      <td>105.206</td>\n",
       "      <td>2039451.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>TXTCLF-364</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-06 12:33:49.456000+00:00</td>\n",
       "      <td>TXTCLF-KER-9</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-06 12:37:44.977000+00:00</td>\n",
       "      <td>231</td>\n",
       "      <td>keras</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-06 12:37:44.977000+00:00</td>\n",
       "      <td>235.507</td>\n",
       "      <td>13422231.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>TXTCLF-362</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06 12:30:34.135000+00:00</td>\n",
       "      <td>TXTCLF-KER-8</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-06 12:30:34.392000+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>keras</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-06 12:30:34.392000+00:00</td>\n",
       "      <td>0.257</td>\n",
       "      <td>251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06 12:18:54.909000+00:00</td>\n",
       "      <td>TXTCLF-KER-7</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-06 12:20:52.060000+00:00</td>\n",
       "      <td>89</td>\n",
       "      <td>keras</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-06 12:20:52.060000+00:00</td>\n",
       "      <td>117.145</td>\n",
       "      <td>11255451.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>TXTCLF-358</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-05 18:25:49.330000+00:00</td>\n",
       "      <td>TXTCLF-KER-6</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-05 18:27:25.769000+00:00</td>\n",
       "      <td>82</td>\n",
       "      <td>keras</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-05 18:27:25.769000+00:00</td>\n",
       "      <td>96.435</td>\n",
       "      <td>11255451.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>TXTCLF-356</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-05 18:09:11.474000+00:00</td>\n",
       "      <td>TXTCLF-KER-5</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-05 18:10:57.264000+00:00</td>\n",
       "      <td>93</td>\n",
       "      <td>keras</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-05 18:10:57.264000+00:00</td>\n",
       "      <td>105.786</td>\n",
       "      <td>11255451.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>TXTCLF-354</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-05 18:00:54.375000+00:00</td>\n",
       "      <td>TXTCLF-KER-4</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-05 18:03:31.043000+00:00</td>\n",
       "      <td>140</td>\n",
       "      <td>keras</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-05 18:03:31.043000+00:00</td>\n",
       "      <td>156.663</td>\n",
       "      <td>11255731.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>TXTCLF-352</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-05 17:57:35.457000+00:00</td>\n",
       "      <td>TXTCLF-KER-3</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-06 12:45:01.920000+00:00</td>\n",
       "      <td>137</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-06 12:45:01.920000+00:00</td>\n",
       "      <td>191.548</td>\n",
       "      <td>11255454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>TXTCLF-350</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-05 17:35:27.859000+00:00</td>\n",
       "      <td>TXTCLF-KER-2</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-05 18:00:09.752000+00:00</td>\n",
       "      <td>123</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-05 18:16:47.766000+00:00</td>\n",
       "      <td>2479.781</td>\n",
       "      <td>11255454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>TXTCLF-348</td>\n",
       "      <td>Keras text classification</td>\n",
       "      <td>https://app.neptune.ai/showcase/project-text-c...</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-05 17:26:18.799000+00:00</td>\n",
       "      <td>TXTCLF-KER-1</td>\n",
       "      <td>TXTCLF-KER</td>\n",
       "      <td>2023-01-05 17:39:34.330000+00:00</td>\n",
       "      <td>49</td>\n",
       "      <td>Untitled</td>\n",
       "      <td>siddhant.sadangi</td>\n",
       "      <td>2023-01-05 18:16:47.943000+00:00</td>\n",
       "      <td>2383.721</td>\n",
       "      <td>4529.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>['accuracy']</td>\n",
       "      <td>adam</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sys/creation_time         sys/id sys/model_id  \\\n",
       "0  2023-03-06 16:34:05.166000+00:00  TXTCLF-KER-11   TXTCLF-KER   \n",
       "1  2023-01-06 12:43:16.770000+00:00  TXTCLF-KER-10   TXTCLF-KER   \n",
       "2  2023-01-06 12:33:49.456000+00:00   TXTCLF-KER-9   TXTCLF-KER   \n",
       "3  2023-01-06 12:30:34.135000+00:00   TXTCLF-KER-8   TXTCLF-KER   \n",
       "4  2023-01-06 12:18:54.909000+00:00   TXTCLF-KER-7   TXTCLF-KER   \n",
       "5  2023-01-05 18:25:49.330000+00:00   TXTCLF-KER-6   TXTCLF-KER   \n",
       "6  2023-01-05 18:09:11.474000+00:00   TXTCLF-KER-5   TXTCLF-KER   \n",
       "7  2023-01-05 18:00:54.375000+00:00   TXTCLF-KER-4   TXTCLF-KER   \n",
       "8  2023-01-05 17:57:35.457000+00:00   TXTCLF-KER-3   TXTCLF-KER   \n",
       "9  2023-01-05 17:35:27.859000+00:00   TXTCLF-KER-2   TXTCLF-KER   \n",
       "10 2023-01-05 17:26:18.799000+00:00   TXTCLF-KER-1   TXTCLF-KER   \n",
       "\n",
       "              sys/modification_time  sys/monitoring_time  sys/name  \\\n",
       "0  2023-03-06 16:45:27.866000+00:00                  658     keras   \n",
       "1  2023-01-06 12:45:01.981000+00:00                   92     keras   \n",
       "2  2023-01-06 12:37:44.977000+00:00                  231     keras   \n",
       "3  2023-01-06 12:30:34.392000+00:00                    1     keras   \n",
       "4  2023-01-06 12:20:52.060000+00:00                   89     keras   \n",
       "5  2023-01-05 18:27:25.769000+00:00                   82     keras   \n",
       "6  2023-01-05 18:10:57.264000+00:00                   93     keras   \n",
       "7  2023-01-05 18:03:31.043000+00:00                  140     keras   \n",
       "8  2023-01-06 12:45:01.920000+00:00                  137  Untitled   \n",
       "9  2023-01-05 18:00:09.752000+00:00                  123  Untitled   \n",
       "10 2023-01-05 17:39:34.330000+00:00                   49  Untitled   \n",
       "\n",
       "           sys/owner                    sys/ping_time  sys/running_time  \\\n",
       "0   siddhant.sadangi 2023-03-06 16:56:32.444000+00:00          1347.211   \n",
       "1   siddhant.sadangi 2023-01-06 12:45:01.981000+00:00           105.206   \n",
       "2   siddhant.sadangi 2023-01-06 12:37:44.977000+00:00           235.507   \n",
       "3   siddhant.sadangi 2023-01-06 12:30:34.392000+00:00             0.257   \n",
       "4   siddhant.sadangi 2023-01-06 12:20:52.060000+00:00           117.145   \n",
       "5   siddhant.sadangi 2023-01-05 18:27:25.769000+00:00            96.435   \n",
       "6   siddhant.sadangi 2023-01-05 18:10:57.264000+00:00           105.786   \n",
       "7   siddhant.sadangi 2023-01-05 18:03:31.043000+00:00           156.663   \n",
       "8   siddhant.sadangi 2023-01-06 12:45:01.920000+00:00           191.548   \n",
       "9   siddhant.sadangi 2023-01-05 18:16:47.766000+00:00          2479.781   \n",
       "10  siddhant.sadangi 2023-01-05 18:16:47.943000+00:00          2383.721   \n",
       "\n",
       "      sys/size  ... params/dropout params/kernel_size          params/loss  \\\n",
       "0   10993265.0  ...            0.5                  5  binary_crossentropy   \n",
       "1    2039451.0  ...            0.5                  7  binary_crossentropy   \n",
       "2   13422231.0  ...            0.5                  4  binary_crossentropy   \n",
       "3        251.0  ...            0.5                  4  binary_crossentropy   \n",
       "4   11255451.0  ...            0.5                  7  binary_crossentropy   \n",
       "5   11255451.0  ...            0.5                  7  binary_crossentropy   \n",
       "6   11255451.0  ...            0.5                  7  binary_crossentropy   \n",
       "7   11255731.0  ...            0.5                  7  binary_crossentropy   \n",
       "8   11255454.0  ...            0.5                  7  binary_crossentropy   \n",
       "9   11255454.0  ...            0.5                  7  binary_crossentropy   \n",
       "10      4529.0  ...            0.5                  7  binary_crossentropy   \n",
       "\n",
       "    params/metrics params/optimizer  params/strides      run/id  \\\n",
       "0              NaN             adam               2  TXTCLF-379   \n",
       "1     ['accuracy']             adam               3  TXTCLF-364   \n",
       "2     ['accuracy']             adam               3  TXTCLF-362   \n",
       "3     ['accuracy']             adam               3         NaN   \n",
       "4     ['accuracy']             adam               3  TXTCLF-358   \n",
       "5     ['accuracy']             adam               3  TXTCLF-356   \n",
       "6     ['accuracy']             adam               3  TXTCLF-354   \n",
       "7     ['accuracy']             adam               3  TXTCLF-352   \n",
       "8     ['accuracy']             adam               3  TXTCLF-350   \n",
       "9     ['accuracy']             adam               3  TXTCLF-348   \n",
       "10    ['accuracy']             adam               3         NaN   \n",
       "\n",
       "                     run/name  \\\n",
       "0   Keras text classification   \n",
       "1   Keras text classification   \n",
       "2   Keras text classification   \n",
       "3                         NaN   \n",
       "4   Keras text classification   \n",
       "5   Keras text classification   \n",
       "6   Keras text classification   \n",
       "7   Keras text classification   \n",
       "8   Keras text classification   \n",
       "9   Keras text classification   \n",
       "10                        NaN   \n",
       "\n",
       "                                              run/url  \\\n",
       "0   https://app.neptune.ai/showcase/project-text-c...   \n",
       "1   https://app.neptune.ai/showcase/project-text-c...   \n",
       "2   https://app.neptune.ai/showcase/project-text-c...   \n",
       "3                                                 NaN   \n",
       "4   https://app.neptune.ai/showcase/project-text-c...   \n",
       "5   https://app.neptune.ai/showcase/project-text-c...   \n",
       "6   https://app.neptune.ai/showcase/project-text-c...   \n",
       "7   https://app.neptune.ai/showcase/project-text-c...   \n",
       "8   https://app.neptune.ai/showcase/project-text-c...   \n",
       "9   https://app.neptune.ai/showcase/project-text-c...   \n",
       "10                                                NaN   \n",
       "\n",
       "                                     serialized_model  \n",
       "0   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "1   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "2   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "3                                                 NaN  \n",
       "4   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "5   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "6   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "7   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "8   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "9   {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "10  {\"class_name\": \"Functional\", \"config\": {\"name\"...  \n",
       "\n",
       "[11 rows x 25 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with neptune.init_model(with_id=f\"{project_key}-KER\") as model:\n",
    "    model_versions_df = model.fetch_model_versions_table().to_pandas()\n",
    "model_versions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_models = model_versions_df[model_versions_df[\"sys/stage\"] == \"production\"][\"sys/id\"]\n",
    "assert (\n",
    "    len(production_models) == 1\n",
    "), f\"Multiple model versions found in production: {production_models.values}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model in production: TXTCLF-KER-10\n"
     ]
    }
   ],
   "source": [
    "prod_model_id = production_models.values[0]\n",
    "print(f\"Current model in production: {prod_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-10\n"
     ]
    }
   ],
   "source": [
    "npt_prod_model = neptune.init_model_version(with_id=prod_model_id)\n",
    "npt_prod_model_params = npt_prod_model[\"params\"].fetch()\n",
    "prod_model = tf.keras.models.model_from_json(npt_prod_model[\"serialized_model\"].fetch())\n",
    "\n",
    "npt_prod_model[\"model_weights\"].download()\n",
    "prod_model.load_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) Evaluate current model on lastest test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Neptune) Fetch data parameters from the run that created the model to preserve data preprocessing\n",
    "We reinitialize the run that created the current champion model to fetch the data parameters. This is done in \"read-only\" mode to prevent accidental modification of the metadata already logged to the run.  \n",
    "Read about the \"read-only\" mode and other connection modes here: https://docs.neptune.ai/api/connection_modes/#read-only-mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-364\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-364/metadata\n",
      "{'batch_size': 32, 'embedding_dim': 128, 'max_features': 2000, 'seed': 1, 'sequence_length': 500, 'validation_split': 0.2}\n"
     ]
    }
   ],
   "source": [
    "prod_run_id = npt_prod_model[\"run/id\"].fetch()\n",
    "\n",
    "with neptune.init_run(prod_run_id, mode=\"read-only\") as prod_run:\n",
    "    prod_data_params = prod_run[\"data/params\"].fetch()\n",
    "\n",
    "print(prod_data_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing test data according to fetched data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Number of batches in raw_train_ds: 625\n",
      "Number of batches in raw_val_ds: 157\n",
      "Number of batches in raw_test_ds: 782\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    \"../data/test\", batch_size=prod_data_params[\"batch_size\"]\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=prod_data_params[\"max_features\"],\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=prod_data_params[\"sequence_length\"],\n",
    ")\n",
    "\n",
    "text_ds = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)\n",
    "\n",
    "# Vectorize the data.\n",
    "test_ds = raw_test_ds.map(vectorize_text)\n",
    "\n",
    "# Do async prefetching / buffering of the data for best performance on GPU.\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 12ms/step - loss: 0.3456 - accuracy: 0.8642\n"
     ]
    }
   ],
   "source": [
    "# using the model's original loss and optimizer, but the current metric\n",
    "prod_model.compile(\n",
    "    loss=npt_prod_model_params[\"loss\"],\n",
    "    optimizer=npt_prod_model_params[\"optimizer\"],\n",
    "    metrics=model_params[\"metrics\"],\n",
    ")\n",
    "\n",
    "_, prod_model_acc = prod_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Neptune) If challenger model outperforms production model, promote it to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champion model accuracy: 0.8642399907112122\n",
      "Challenger model accuracy: 0.8517199754714966\n",
      "Archiving challenger model\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-10/metadata\n"
     ]
    }
   ],
   "source": [
    "print(f\"Champion model accuracy: {prod_model_acc}\\nChallenger model accuracy: {curr_model_acc}\")\n",
    "\n",
    "if curr_model_acc > prod_model_acc:\n",
    "    print(\"Promoting challenger to champion\")\n",
    "    npt_prod_model.change_stage(\"archived\")\n",
    "    model_version.change_stage(\"production\")\n",
    "else:\n",
    "    print(\"Archiving challenger model\")\n",
    "    model_version.change_stage(\"archived\")\n",
    "\n",
    "npt_prod_model.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Neptune) Stop tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/showcase/project-text-classification/m/TXTCLF-KER/v/TXTCLF-KER-11/metadata\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/showcase/project-text-classification/e/TXTCLF-379/metadata\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/showcase/project-text-classification/metadata\n"
     ]
    }
   ],
   "source": [
    "model_version.stop()\n",
    "run.stop()\n",
    "project.stop()"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "neptune": {
   "notebookId": "9828a187-2d06-4d81-847c-61066b3f0790",
   "projectVersion": 2
  },
  "vscode": {
   "interpreter": {
    "hash": "a9715cf0b0024f6e1c62cb31a4f1f43970eb41991212681878768b4bfe53050a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
