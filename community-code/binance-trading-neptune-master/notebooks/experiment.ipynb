{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f3a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb30be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_binance_data(config):\n",
    "    \"\"\"Download historical data from Binance\"\"\"\n",
    "    base_url = \"https://data.binance.vision/data/spot/monthly/klines\"\n",
    "    os.makedirs(os.path.join(config[\"data_dir\"], config[\"interval\"]), exist_ok=True)\n",
    "\n",
    "    for d in pd.date_range(config[\"start_date\"], config[\"end_date\"], freq=\"M\"):\n",
    "        # Fixed filename formatting - using month number directly\n",
    "        filename = f\"{config['ticker']}-{config['interval']}-{d.year}-{d.month:02d}.zip\"\n",
    "        save_path = os.path.join(config[\"data_dir\"], config[\"interval\"], filename)\n",
    "\n",
    "        if not os.path.exists(save_path):\n",
    "            url = f\"{base_url}/{config['ticker']}/{config['interval']}/{filename}\"\n",
    "            print(f\"Trying to download: {url}\")  # Added for debugging\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(save_path, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                print(f\"Downloaded {filename}\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Failed to download {filename} (Status code: {response.status_code})\"\n",
    "                )\n",
    "\n",
    "\n",
    "# Run this once to download the data\n",
    "# download_binance_data(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e688bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..', 'data',  'BTCUSDT', '1h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066c1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = {\n",
    "  'data_dir': os.path.join('..', 'data',  'BTCUSDT'),\n",
    "  'names': [\"open time\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "            \"close time\", \"quote asset volume\", \"number of trades\",\n",
    "            \"taker buy base asset volume\", \"taker buy quote asset volume\", \"date\"],\n",
    "  'columns': [\"open time\", \"open\", \"high\", \"low\", \"close\", \"volume\"], \n",
    "  'start_date': '2017-08', \n",
    "  'end_date': '2022-06', \n",
    "  'start_date_training': '2018-01-01',\n",
    "  'ticker': 'BTCUSDT',\n",
    "  'interval': '1h', \n",
    "}\n",
    "\n",
    "class DataLoader():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data = self.load_data()\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load data and return prepared data frame\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame()\n",
    "        for d in tqdm(pd.date_range(self.config['start_date'], self.config['end_date'], freq='M')):\n",
    "            temp_dir = os.path.join(self.config['data_dir'], self.config['interval'],\n",
    "                                    '{}-{}-{}-{:02}.zip'.format(self.config['ticker'],\n",
    "                                                         self.config['interval'], \n",
    "                                                         d.year, \n",
    "                                                         d.month))\n",
    "            df = df.append(pd.read_csv(temp_dir, names=self.config['names']))\n",
    "        \n",
    "        df = df[self.config['columns']]\n",
    "        df['date'] = pd.to_datetime(df['open time'], unit='ms')\n",
    "        df = df.sort_values(by = 'date')\n",
    "        \n",
    "        d1 = df['date'].to_list()[0]\n",
    "        d2 = df['date'].to_list()[-1]\n",
    "        \n",
    "        df = df.set_index('date')\n",
    "        df = df.reindex(pd.date_range(d1, d2, freq='H')).fillna(method = 'ffill')\n",
    "        \n",
    "        #df[\"log_return\"] = np.log(df['close'] / df['close'].shift(1))\n",
    "        df[\"return\"] = df['close'].pct_change()\n",
    "        df = df.drop('open time', axis=1)\n",
    "        return df\n",
    "    \n",
    "    def generate_features(self):\n",
    "        \n",
    "        for i in [5, 10, 15, 20]:\n",
    "            self.data[f'MA_{i}'] = talib.MA(self.data['close'], timeperiod=i)\n",
    "            self.data[f'MA_{i}'] = self.data[f'MA_{i}']/self.data['close']\n",
    "        \n",
    "        for i in [7, 14, 21]:\n",
    "            self.data[f'RSI_{i}'] = talib.RSI(self.data['close'], timeperiod=i)\n",
    "            self.data[f'MFI_{i}'] = talib.MFI(self.data['high'],\n",
    "                                              self.data['low'],\n",
    "                                              self.data['close'],\n",
    "                                              self.data['volume'],\n",
    "                                              timeperiod=i)\n",
    "        \n",
    "        self.data['target_return'] = self.data['return'].shift(-1)\n",
    "        self.data['target'] = self.data['target_return'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        self.data = self.data.dropna() \n",
    "        self.data = self.data[self.data.index >= pd.to_datetime(self.config['start_date_training'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DataLoader(data_config)\n",
    "df = dt.load_data()\n",
    "dt.generate_features()\n",
    "dt.data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e354921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "trader_config = {\n",
    "    'features': ['MA_5', 'MA_10', 'MA_15', 'MA_20',\n",
    "                 'RSI_7', 'MFI_7', 'RSI_14', 'MFI_14',\n",
    "                 'RSI_21', 'MFI_21'],\n",
    "    # out of sample start date\n",
    "    'oos_start_date': '2022-01-01', \n",
    "    # look back (training size) in days\n",
    "    'look_back': 90,\n",
    "    # training size\n",
    "    'step': 30,\n",
    "}\n",
    "\n",
    "class HourlyBacktester():\n",
    "    def __init__(self, data, config):\n",
    "        self.config = config\n",
    "        self.full_data = data\n",
    "        self.df_res = None\n",
    "        \n",
    "    def get_oos_data(self):\n",
    "        \"\"\"\n",
    "            Returns out-of-sample data\n",
    "        \"\"\"\n",
    "        return self.full_data[self.full_data.index >= pd.to_datetime(self.config['oos_start_date'])]\n",
    "    \n",
    "    def get_is_data(self):\n",
    "        \"\"\"\n",
    "            Returns in-sample data\n",
    "        \"\"\"\n",
    "        return self.full_data[self.full_data.index < pd.to_datetime(self.config['oos_start_date'])]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_model(xgb_param):\n",
    "        \"\"\"\n",
    "            Returns model\n",
    "        \"\"\"\n",
    "        params = xgb_param.copy()\n",
    "        params[\"eval_metric\"] = \"logloss\"  # Add eval_metric to model parameters\n",
    "        return XGBClassifier(**params, objective=\"binary:logistic\")\n",
    "\n",
    "    def apply_strategy(self, params, look_back, oos=False):\n",
    "        \"\"\"\n",
    "            The main logic of the strategy\n",
    "        \"\"\"\n",
    "        self.config[\"look_back\"] = look_back\n",
    "\n",
    "        if oos:\n",
    "            df = self.get_oos_data()\n",
    "            dft = self.get_is_data()\n",
    "            df = dft[-self.config['look_back']:].append(df)\n",
    "        else:\n",
    "            df = self.get_is_data()\n",
    "            \n",
    "        self.df_res = pd.DataFrame()\n",
    "        i = 0\n",
    "        with tqdm(total = len(df)) as pbar:\n",
    "            pbar.update(self.config['look_back']*24)\n",
    "            while True:\n",
    "                train_start = i*self.config['step']*24\n",
    "                train_end = train_start + self.config['look_back']*24\n",
    "                test_end = train_end + self.config['step']*24\n",
    "                if train_end >= len(df):\n",
    "                    break\n",
    "\n",
    "                df_train = df[train_start:train_end]\n",
    "                df_test = df[train_end:test_end]\n",
    "\n",
    "                x_tr = df_train[self.config['features']]\n",
    "                x_test = df_test[self.config['features']]\n",
    "                y_tr = df_train['target']\n",
    "\n",
    "                clf = self.get_model(params)\n",
    "                # Remove eval_metric from fit() call\n",
    "                clf.fit(x_tr, y_tr)\n",
    "\n",
    "                pred = clf.predict(x_test)\n",
    "                df_pred = pd.DataFrame({\n",
    "                    'date': df_test.index,\n",
    "                    'target_return': df_test['target_return'],\n",
    "                    'target': df_test['target'],\n",
    "                    'prediction': pred\n",
    "                })\n",
    "                if len(self.df_res):\n",
    "                    self.df_res = self.df_res.append(df_pred)\n",
    "                else:\n",
    "                    self.df_res = df_pred\n",
    "                pbar.update(self.config[\"step\"] * 24)\n",
    "                i += 1\n",
    "\n",
    "    def get_score(self):\n",
    "        \n",
    "        self.df_res['hourly_return'] = self.df_res[['target_return', 'target', 'prediction']].apply(\n",
    "           lambda row: np.abs(row[0]) if row[1] == row[2] else -np.abs(row[0]) , axis=1\n",
    "        )\n",
    "        \n",
    "        self.df_res['cum_ret'] = self.df_res['hourly_return'].cumsum()\n",
    "        \n",
    "        return self.df_res['cum_ret'].to_list()[-1]\n",
    "\n",
    "    def objective(self, trial):\n",
    "        \n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 350, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.50, 0.90),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 0.90),\n",
    "            'gamma': trial.suggest_int('gamma', 0, 20), \n",
    "        }\n",
    "        \n",
    "        look_back = trial.suggest_int('look_back', 30, 180)\n",
    "        \n",
    "        self.apply_strategy(params, look_back)\n",
    "        \n",
    "        return self.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd48db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "import neptune\n",
    "import neptune.integrations.optuna as optuna_utils\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=os.getenv(\"NEPTUNE_PROJECT_NAME\"),\n",
    "    api_token=os.getenv(\"NEPTUNE_API_TOKEN\"),\n",
    ")\n",
    "\n",
    "neptune_callback = optuna_utils.NeptuneCallback(run)\n",
    "\n",
    "hb = HourlyBacktester(dt.data, trader_config)\n",
    "n_trials = 20\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(hb.objective, n_trials=n_trials, callbacks=[neptune_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c209417",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "look_back = best_params.pop('look_back')\n",
    "\n",
    "hb = HourlyBacktester(dt.data, trader_config)\n",
    "hb.apply_strategy( best_params, look_back)\n",
    "hb.get_score()\n",
    "\n",
    "hb.df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac11523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 7)\n",
    "hb.df_res['buy_and_hold_ret'] = (hb.df_res['target_return'] + 1).cumprod() - 1\n",
    "hb.df_res[['cum_ret', 'buy_and_hold_ret']].plot()\n",
    "plt.legend(['Cumulative return XGB', 'Cumulative return buy and hold'])\n",
    "plt.grid()\n",
    "plt.ylabel('Cumulative return')\n",
    "plt.title('Cumulative return without transaction costs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad1fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb = HourlyBacktester(dt.data, trader_config)\n",
    "hb.apply_strategy( best_params, look_back, oos=True)\n",
    "hb.get_score()\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 7)\n",
    "hb.df_res['buy_and_hold_ret'] = (hb.df_res['target_return'] + 1).cumprod() - 1\n",
    "hb.df_res[['cum_ret', 'buy_and_hold_ret']].plot()\n",
    "plt.legend(['Cumulative return XGB', 'Cumulative return buy and hold'])\n",
    "plt.grid()\n",
    "plt.ylabel('Cumulative return')\n",
    "plt.title('Out-of-sample cumulative return without transaction costs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536867e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import Mock\n",
    "\n",
    "json = Mock()\n",
    "json.order = lambda x, z: {\"executedQty\":1,\n",
    "                             \"cummulativeQuoteQty\":np.random.rand()+1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8bffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binance-trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
