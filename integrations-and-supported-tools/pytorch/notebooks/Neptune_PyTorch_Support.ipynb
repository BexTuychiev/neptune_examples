{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Neptune_PyTorch_Support.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b3b6f568bdd74e02a3b4af71fc45b14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b984a82a839487781f05e42aac4b13c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_19ef8d7b71cc4a95b576c9be32ea3f76",
              "IPY_MODEL_7664a9d0abda44c2b0b0ea487eca91c1"
            ]
          }
        },
        "0b984a82a839487781f05e42aac4b13c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19ef8d7b71cc4a95b576c9be32ea3f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0637cc0d2dd449889d3d5a8e2a161ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f57fdc29215f4404b36e1cc0036436d2"
          }
        },
        "7664a9d0abda44c2b0b0ea487eca91c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_741c672a9187432ab63a757659232bcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [02:00&lt;00:00, 1417583.66it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ede1aff20bb449c8c2f391f2fb5864d"
          }
        },
        "a0637cc0d2dd449889d3d5a8e2a161ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f57fdc29215f4404b36e1cc0036436d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "741c672a9187432ab63a757659232bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ede1aff20bb449c8c2f391f2fb5864d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THIzFFk81nme"
      },
      "source": [
        "# Neptune + PyTorch\n",
        "\n",
        "## Before you start\n",
        "\n",
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54CFqKRANLK5"
      },
      "source": [
        "!pip install -q neptune-client==0.9.9 numpy==1.20.3 torch==1.8.1 torchvision==0.9.1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90-k5eK205uM"
      },
      "source": [
        "# Basic example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXve6tFt1dLd"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1NVL5h6MlLq"
      },
      "source": [
        "from numpy.random import permutation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import neptune.new as neptune\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfqmkNLB1SRu"
      },
      "source": [
        "## Step 1: Create a Neptune *Run*\n",
        "\n",
        "To log metadata to the Neptune project, you need the `project name` and the `api_token`.\n",
        "\n",
        "To make this example easy to follow, we have created a public project **'common/optuna-integration'** and a shared user **'neptuner'** with the API token **'ANONYMOUS'**. As you will see in the code cell below.\n",
        "\n",
        "**(Optional)** To log to your Neptune project:\n",
        "\n",
        "* [Create a Neptune account](https://app.neptune.ai/register/)\n",
        "\n",
        "* [Find your API token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token)\n",
        "* [Find your project name](https://docs.neptune.ai/getting-started/installation#setting-the-project-name)\n",
        "\n",
        "Pass your credentials to project and api_token arguments of neptune.init()\n",
        "\n",
        "`run = neptune.init(api_token='<YOUR_API_TOKEN>', project='<YOUR_WORKSPACE/YOUR_PROJECT>')` # pass your credentials\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIAK4NasfQ_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e5d8d5-278e-4d72-cb0f-3703fb60e9f6"
      },
      "source": [
        "run = neptune.init(project = 'common/pytorch-integration', tags='Colab Notebook', api_token='ANONYMOUS')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://app.neptune.ai/common/pytorch-integration/e/PYTOR1-36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4StPQOmmh_d"
      },
      "source": [
        "Running this cell creates a Run in Neptune, and you can log model building metadata to it.\n",
        "\n",
        "**Click on the link above to open the Run in Neptune UI.** For now, it is empty, but you should keep the tab open to see what happens next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WbPjLDk1GcC"
      },
      "source": [
        "## Step 2: Log config and hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVJKNQxIYPAC"
      },
      "source": [
        "### Log Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_8vefGCNBIJ"
      },
      "source": [
        "parameters = {'lr': 1e-2,\n",
        "              'bs': 128,\n",
        "              'input_sz': 32 * 32 * 3,\n",
        "              'n_classes': 10,\n",
        "              'model_filename': 'basemodel',\n",
        "              'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "              }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Ig4exNSMwE"
      },
      "source": [
        "run['config/hyperparameters'] = parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2rAXguq0_IZ"
      },
      "source": [
        "### Log Config\n",
        "Model and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwdf0rrklZWi"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(input_sz, hidden_dim*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim//2, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = input.view(-1, 32* 32 * 3)\n",
        "        return self.main(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i19Y0g3YGvV2"
      },
      "source": [
        "model = BaseModel(parameters[\"input_sz\"], parameters[\"input_sz\"], parameters[\"n_classes\"]).to(parameters[\"device\"])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=parameters[\"lr\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viTM9XYl4-C0"
      },
      "source": [
        "Log model, criterion and optimizer name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iZSQE5DYyqX"
      },
      "source": [
        "run[\"config/model\"] = type(model).__name__\n",
        "run[\"config/criterion\"] = type(criterion).__name__\n",
        "run[\"config/optimizer\"] = type(optimizer).__name__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2gKRp-8THxa"
      },
      "source": [
        "data_dir = 'data/CIFAR10'\n",
        "compressed_ds = './data/CIFAR10/cifar-10-python.tar.gz'\n",
        "data_tfms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            \n",
        "        ])\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMa-mrc64qjz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "b3b6f568bdd74e02a3b4af71fc45b14a",
            "0b984a82a839487781f05e42aac4b13c",
            "19ef8d7b71cc4a95b576c9be32ea3f76",
            "7664a9d0abda44c2b0b0ea487eca91c1",
            "a0637cc0d2dd449889d3d5a8e2a161ec",
            "f57fdc29215f4404b36e1cc0036436d2",
            "741c672a9187432ab63a757659232bcd",
            "0ede1aff20bb449c8c2f391f2fb5864d"
          ]
        },
        "outputId": "6d9e9b7e-297d-4278-da08-6c50cdac4b86"
      },
      "source": [
        "trainset = datasets.CIFAR10(data_dir, transform=data_tfms['train'], \n",
        "                            download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, \n",
        "                                          batch_size=parameters['bs'],\n",
        "                                          shuffle=True, num_workers=2)\n",
        "validset = datasets.CIFAR10(data_dir, train=False,\n",
        "                            transform=data_tfms['train'],\n",
        "                            download=True)\n",
        "validloader = torch.utils.data.DataLoader(validset, \n",
        "                                          batch_size=parameters['bs'], \n",
        "                                          num_workers=2)\n",
        "      \n",
        "dataset_size = {'train': len(trainset), 'val': len(validset)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/CIFAR10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3b6f568bdd74e02a3b4af71fc45b14a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/CIFAR10/cifar-10-python.tar.gz to data/CIFAR10\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mXZEVnl4-C1"
      },
      "source": [
        "Log dataset details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKFjiUDqgTqT"
      },
      "source": [
        "run[\"config/dataset/path\"] = data_dir\n",
        "run[\"config/dataset/transforms\"] = data_tfms\n",
        "run[\"config/dataset/size\"] = dataset_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRaqN0ug1KP_"
      },
      "source": [
        "## Step 3: Log losses and metrics \n",
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgGfdruzNB3t"
      },
      "source": [
        "for i, (x, y) in enumerate(trainloader, 0):\n",
        "    x, y = x.to(parameters['device']), y.to(parameters['device'])\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model.forward(x)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    loss = criterion(outputs, y)\n",
        "    acc = (torch.sum(preds == y.data)) / len(x)\n",
        "\n",
        "    run[\"training/batch/loss\"].log(loss)\n",
        "    \n",
        "    run[\"training/batch/acc\"].log(acc)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mMjQTFbUgZq"
      },
      "source": [
        "# More Options"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOfczeu6loOK"
      },
      "source": [
        "## Step 4: Log model arch and weights\n",
        "You to have saved these files to disk using a helper function like save_model before trying to upload to neptune "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFkn6KKK4-C1"
      },
      "source": [
        "fname = parameters[\"model_filename\"]\n",
        "\n",
        "# Saving model architecture to .txt\n",
        "with open(f\"./{fname}_arch.txt\", \"w\") as f:  f.write(str(model))\n",
        "# Saving model weights .pth\n",
        "torch.save(model.state_dict(), f\"./{fname}.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emMQ4KIXllN5"
      },
      "source": [
        "run[f\"io_files/artifacts/{parameters['model_filename']}_arch\"].upload(f\"./{parameters['model_filename']}_arch.txt\")\n",
        "run[f\"io_files/artifacts/{parameters['model_filename']}\"].upload(f\"./{parameters['model_filename']}.pth\")\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxnCGtFaNxRC"
      },
      "source": [
        "## Step 5: Log images "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqkTf7YZTEG6"
      },
      "source": [
        "### Log Torch Tensors as images\n",
        "You can log PyTorch Tensors (2d or 3d) directly from the memory, and have them visualized as an image. For more about logging torch tensor see [what you can log and display](https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#pytorch-tensor)\n",
        "and [field types](https://docs.neptune.ai/api-reference/field-types#fileseries) to understand how to upload multiple files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a9vqgOB4-C2"
      },
      "source": [
        "* Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tuNzGBatA-L"
      },
      "source": [
        "from neptune.new.types import File\n",
        "import torch.nn.functional as F\n",
        "\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "dataiter = iter(validloader)\n",
        "images, labels = dataiter.next()\n",
        "model.eval()\n",
        "\n",
        "\n",
        "if torch.cuda.is_available(): model.to(\"cpu\")\n",
        "\n",
        "n_samples = 50\n",
        "img = images[:n_samples]\n",
        "probs = F.softmax(model(img),dim=1)\n",
        "probs = probs.data.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PDdbuhV4-C2"
      },
      "source": [
        "*  Decode probs and Log images tensors\n",
        "*  Log Series of Tensors as Image and Predictions. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iqa2yfe4-C2"
      },
      "source": [
        "for i, ps in enumerate(probs):\n",
        "    pred = classes[np.argmax(ps)]\n",
        "    gt = classes[labels[i]]\n",
        "    description = \"\\n\".join([\"class {}: {}%\".format(classes[n], round(p*100, 2)) for n, p in enumerate(ps)])\n",
        "    \n",
        "    run['images/predictions'].log(File.as_image(img[i].squeeze().permute(2,1,0).clip(0,1)), name=f'{i}_{pred}_{gt}', description=description)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhE6C9xv-lXK"
      },
      "source": [
        "# Stop run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Meg02T9p9314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8f1ceb-b376-4ad1-80aa-bee415bf2237"
      },
      "source": [
        "run.stop() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All 1 operations synced, thanks for waiting!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32b8HLFuA2jt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}