{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Neptune_PyTorch_Support.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THIzFFk81nme"
      },
      "source": [
        "# Neptune + PyTorch\n",
        "\n",
        "## Before you start\n",
        "\n",
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54CFqKRANLK5"
      },
      "source": [
        "!pip install --quiet neptune-client==0.9.9 numpy==1.20.3 torch==1.8.1 torchvision==0.9.1 "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90-k5eK205uM"
      },
      "source": [
        "# Basic example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXve6tFt1dLd"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1NVL5h6MlLq"
      },
      "source": [
        "from numpy.random import permutation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import neptune.new as neptune\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfqmkNLB1SRu"
      },
      "source": [
        "## Step 1: Create a Neptune *Run*\n",
        "\n",
        "To log metadata to the Neptune project, you need the `project name` and the `api_token`.\n",
        "\n",
        "To make this example easy to follow, we have created a public project **'common/optuna-integration'** and a shared user **'neptuner'** with the API token **'ANONYMOUS'**. As you will see in the code cell below.\n",
        "\n",
        "**(Optional)** To log to your Neptune project:\n",
        "\n",
        "* [Create a Neptune account](https://app.neptune.ai/register/)\n",
        "\n",
        "* [Find your API token](https://docs.neptune.ai/getting-started/installation#authentication-neptune-api-token)\n",
        "* [Find your project name](https://docs.neptune.ai/getting-started/installation#setting-the-project-name)\n",
        "\n",
        "Pass your credentials to project and api_token arguments of neptune.init()\n",
        "\n",
        "`run = neptune.init(api_token='<YOUR_API_TOKEN>', project='<YOUR_WORKSPACE/YOUR_PROJECT>')` # pass your credentials\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIAK4NasfQ_f"
      },
      "source": [
        "run = neptune.init(project = 'common/pytorch-integration', tags='Colab Notebook', api_token='ANONYMOUS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4StPQOmmh_d"
      },
      "source": [
        "Running this cell creates a Run in Neptune, and you can log model building metadata to it.\n",
        "\n",
        "**Click on the link above to open the Run in Neptune UI.** For now, it is empty, but you should keep the tab open to see what happens next"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WbPjLDk1GcC"
      },
      "source": [
        "## Step 2: Log config and hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVJKNQxIYPAC"
      },
      "source": [
        "### Log Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_8vefGCNBIJ"
      },
      "source": [
        "parameters = {'lr': 1e-2,\n",
        "              'bs': 128,\n",
        "              'input_sz': 32 * 32 * 3,\n",
        "              'n_classes': 10,\n",
        "              'epochs': 50,\n",
        "              'model_filename': 'basemodel',\n",
        "              'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "              }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Ig4exNSMwE"
      },
      "source": [
        "run['config/hyperparameters'] = parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2rAXguq0_IZ"
      },
      "source": [
        "### Log Config\n",
        "Model and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwdf0rrklZWi"
      },
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, input_sz, hidden_dim, n_classes):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(input_sz, hidden_dim*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim//2, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = input.view(-1, 32* 32 * 3)\n",
        "        return self.main(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i19Y0g3YGvV2"
      },
      "source": [
        "model = BaseModel(parameters[\"input_sz\"], parameters[\"input_sz\"], parameters[\"n_classes\"]).to(parameters[\"device\"])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=parameters[\"lr\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Log model, criterion and optimizer name"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "run[\"config/model\"] = type(model).__name__\n",
        "run[\"config/criterion\"] = type(criterion).__name__\n",
        "run[\"config/optimizer\"] = type(optimizer).__name__"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "-iZSQE5DYyqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2gKRp-8THxa"
      },
      "source": [
        "data_dir = 'data/CIFAR10'\n",
        "compressed_ds = './data/CIFAR10/cifar-10-python.tar.gz'\n",
        "data_tfms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            \n",
        "        ])\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMa-mrc64qjz"
      },
      "source": [
        "trainset = datasets.CIFAR10(data_dir, transform=data_tfms['train'], \n",
        "                            download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, \n",
        "                                          batch_size=parameters['bs'],\n",
        "                                          shuffle=True, num_workers=2)\n",
        "validset = datasets.CIFAR10(data_dir, train=False,\n",
        "                            transform=data_tfms['train'],\n",
        "                            download=True)\n",
        "validloader = torch.utils.data.DataLoader(validset, \n",
        "                                          batch_size=parameters['bs'], \n",
        "                                          num_workers=2)\n",
        "      \n",
        "dataset_size = {'train': len(trainset), 'val': len(validset)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Log dataset details"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKFjiUDqgTqT"
      },
      "source": [
        "run[\"config/dataset/path\"] = data_dir\n",
        "run[\"config/dataset/transforms\"] = data_tfms\n",
        "run[\"config/dataset/size\"] = dataset_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRaqN0ug1KP_"
      },
      "source": [
        "## Step 3: Log losses and metrics \n",
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgGfdruzNB3t"
      },
      "source": [
        "\n",
        "for epoch in range(parameters['epochs']):\n",
        "\n",
        "    for i, (x, y) in enumerate(trainloader, 0):\n",
        "        x, y = x.to(parameters['device']), y.to(parameters['device'])\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model.forward(x)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, y)\n",
        "        acc = (torch.sum(preds == y.data)) / len(x)\n",
        "\n",
        "        run[\"training/batch/loss\"].log(loss)\n",
        "        \n",
        "        run[\"training/batch/acc\"].log(acc)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mMjQTFbUgZq"
      },
      "source": [
        "# More Options"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOfczeu6loOK"
      },
      "source": [
        "## Step 4: Log model arch and weights\n",
        "You to have saved these files to disk using a helper function like save_model before trying to upload to neptune "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fname = params[\"model_filename\"]\n",
        "\n",
        "# Saving model architecture to .txt\n",
        "with open(f\"./{fname}_arch.txt\", \"w\") as f:  f.write(str(model))\n",
        "# Saving model weights .pth\n",
        "torch.save(model.state_dict(), f\"./{fname}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emMQ4KIXllN5"
      },
      "source": [
        "run[f\"io_files/artifacts/{parameters['model_filename']}_arch\"].upload(f\"./{parameters['model_filename']}_arch.txt\")\n",
        "run[f\"io_files/artifacts/{parameters['model_filename']}\"].upload(f\"./{parameters['model_filename']}.pth\")\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxnCGtFaNxRC"
      },
      "source": [
        "## Step 5: Log images "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqkTf7YZTEG6"
      },
      "source": [
        "### Log Torch Tensors as images\n",
        "You can log PyTorch Tensors (2d or 3d) directly from the memory, and have them visualized as an image. For more about logging torch tensor see [what you can log and display](https://docs.neptune.ai/you-should-know/what-can-you-log-and-display#pytorch-tensor)\n",
        "and [field types](https://docs.neptune.ai/api-reference/field-types#fileseries) to understand how to upload multiple files."
      ]
    },
    {
      "source": [
        "* Get predictions"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tuNzGBatA-L"
      },
      "source": [
        "from neptune.new.types import File\n",
        "import torch.nn.functional as F\n",
        "\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "dataiter = iter(validloader)\n",
        "images, labels = dataiter.next()\n",
        "model.eval()\n",
        "\n",
        "\n",
        "if torch.cuda.is_available(): model.to(\"cpu\")\n",
        "\n",
        "\n",
        "img = images[:n_samples]\n",
        "probs = F.softmax(model(img),dim=1)\n",
        "probs = probs.data.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "*  Decode probs and Log images tensors\n",
        "*  Log Series of Tensors as Image and Predictions. \n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, ps in enumerate(probs):\n",
        "    pred = classes[np.argmax(ps)]\n",
        "    gt = classes[labels[i]]\n",
        "    description = \"\\n\".join([\"class {}: {}%\".format(classes[n], round(p*100, 2)) for n, p in enumerate(ps)])\n",
        "    \n",
        "    run['images/predictions'].log(File.as_image(img[i].squeeze().permute(2,1,0).clip(0,1)), name=f'{i}_{pred}_{gt}', description=description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhE6C9xv-lXK"
      },
      "source": [
        "# Stop run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Meg02T9p9314"
      },
      "source": [
        "run.stop() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}